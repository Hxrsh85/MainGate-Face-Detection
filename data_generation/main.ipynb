{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735794732.006340    9470 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1735794732.009405  119685 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.3), renderer: Mesa Intel(R) Graphics (ADL GT2)\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cropper_img import Cropping\n",
    "cropper = Cropping()\n",
    "import pickle\n",
    "\n",
    "data_path = './cropped_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1735794732.017615  119676 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../model')  # Load the model\n",
    "\n",
    "# Function to preprocess and encode images using a pre-trained model\n",
    "def img_to_encoding(img_array):\n",
    "    img_array = cv2.resize(img_array, (160, 160))  # Resize to the required shape\n",
    "    img_array = np.around(img_array / 255.0, decimals=12)  # Normalize\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    embedding = model.predict_on_batch(img_array)\n",
    "    return embedding / np.linalg.norm(embedding, ord=2)\n",
    "\n",
    "# Function to load image vectors\n",
    "def load_vectors():\n",
    "    img_vectors = []\n",
    "    for dir in os.listdir(data_path):\n",
    "        dir_path = os.path.join(data_path, dir)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            continue\n",
    "        for file in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, file)\n",
    "            img_array = cv2.imread(img_path)\n",
    "            if img_array is None:\n",
    "                print(f\"Error reading {img_path}, skipping...\")\n",
    "                continue\n",
    "            encoding = img_to_encoding(img_array)\n",
    "            img_vectors.append({'name': dir, 'encoding': encoding.flatten()})\n",
    "    return img_vectors\n",
    "\n",
    "# Function to train the KMeans model\n",
    "def train_model(img_vectors, clusters = 5):\n",
    "    X = [img['encoding'] for img in img_vectors]\n",
    "\n",
    "    kmeans = KMeans(n_clusters=clusters, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the vectors...\n",
      "Loaded vectors\n"
     ]
    }
   ],
   "source": [
    "# Function to update the database (10m 42.6s)\n",
    "print(\"Loading the vectors...\")\n",
    "img_vectors = load_vectors()\n",
    "print(\"Loaded vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(file_name, data):\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "    print(f\"List saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List saved to img_vectors.pkl\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN THIS CELL ALWAYS\n",
    "save_list('img_vectors.pkl', img_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list(file_name):\n",
    "    with open(file_name, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    print(f\"List loaded from {file_name}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = train_model(img_vectors, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database updated\n",
      "CPU times: user 1.6 s, sys: 83.1 ms, total: 1.68 s\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = client['optimized_image_db']\n",
    "for img in img_vectors:\n",
    "    class_name = str(kmeans.predict([img['encoding']])[0])\n",
    "    collection = db[class_name]\n",
    "    collection.insert_one({'name': img['name'], 'encoding': img['encoding'].tolist()})\n",
    "print(\"Database updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database updated\n",
      "CPU times: user 556 ms, sys: 61.5 ms, total: 618 ms\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = client['unoptimized_image_db']\n",
    "collection = db['vectors']\n",
    "for img in img_vectors:\n",
    "    collection.insert_one({'name': img['name'], 'encoding': img['encoding'].tolist()})\n",
    "print(\"Database updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_in_collection(img, db):\n",
    "    # print(\"test\")\n",
    "    img_vector = img_to_encoding(img)\n",
    "\n",
    "    img_vector = [img_vector.flatten()]\n",
    "    # print(\"test\")\n",
    "    class_name = str(kmeans.predict(img_vector)[0])\n",
    "    # print(\"test1\")\n",
    "    collection = db[class_name]\n",
    "    vectors = collection.find({})\n",
    "    img_vector = np.array(img_vector)\n",
    "    # print(vectors)\n",
    "    for vector in vectors:\n",
    "        if np.linalg.norm(np.array(vector['encoding']) - img_vector) < 0.85:\n",
    "            return vector['name']\n",
    "    return None\n",
    "\n",
    "def check_in_database(img, db):\n",
    "    img_vector = img_to_encoding(img)\n",
    "    img_vector = img_vector.flatten()\n",
    "    img_vector = np.array(img_vector)\n",
    "    for i in range(5):\n",
    "        collection = db[str(i)]\n",
    "        vectors = collection.find({})\n",
    "        for vector in vectors:\n",
    "            if np.linalg.norm(np.array(vector['encoding']) - img_vector) < 0.85:\n",
    "                return vector['name']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@77.887] global loadsave.cpp:241 findDecoder imread_('./test_images/1859737-6alluarjun.webp'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test_images/1859737-6alluarjun.webp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m cropper\u001b[38;5;241m.\u001b[39mcrop_face(img)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./cropped_data/allu arjun/1546058432_Allu_Arjun.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cropper.crop_face(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in collection\n",
      "Person identified as allu arjun\n",
      "CPU times: user 176 ms, sys: 13.8 ms, total: 189 ms\n",
      "Wall time: 36.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = client['optimized_image_db']\n",
    "person = check_in_collection(img, db)\n",
    "\n",
    "if not person:\n",
    "    print(\"Not found in collection\")\n",
    "    person = check_in_database(img, db)\n",
    "else:\n",
    "    print(\"Found in collection\")\n",
    "    \n",
    "if person:\n",
    "    print(f\"Person identified as {person}\")\n",
    "else:\n",
    "    print(\"Person not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_in_collection_control(img, db):\n",
    "    # print(\"test\")\n",
    "    collection = db['vectors']\n",
    "    img_vector = img_to_encoding(img)\n",
    "\n",
    "    img_vector = [img_vector.flatten()]\n",
    "\n",
    "    vectors = collection.find({})\n",
    "    img_vector = np.array(img_vector)\n",
    "    # print(vectors)\n",
    "    for vector in vectors:\n",
    "        if np.linalg.norm(np.array(vector['encoding']) - img_vector) < 0.85:\n",
    "            return vector['name']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person identified as allu arjun\n",
      "CPU times: user 235 ms, sys: 39.1 ms, total: 274 ms\n",
      "Wall time: 53.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = client['unoptimized_image_db']\n",
    "person = check_in_collection_control(img, db)\n",
    "\n",
    "if person:\n",
    "    print(f\"Person identified as {person}\")\n",
    "else:\n",
    "    print(\"Person not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the databases\n",
    "client.drop_database('optimized_image_db')\n",
    "client.drop_database('unoptimized_image_db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
