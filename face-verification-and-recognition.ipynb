{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc1ugsgmfCd7"
   },
   "source": [
    "<a name='1'></a>\n",
    "# 1 - Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T17:03:16.380981Z",
     "iopub.status.busy": "2024-12-21T17:03:16.380579Z",
     "iopub.status.idle": "2024-12-21T17:03:28.678941Z",
     "shell.execute_reply": "2024-12-21T17:03:28.677674Z",
     "shell.execute_reply.started": "2024-12-21T17:03:16.380943Z"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1690727247385,
     "user": {
      "displayName": "Diaa Essam",
      "userId": "00529409558760259485"
     },
     "user_tz": -180
    },
    "id": "2E7KsQwZfCd7",
    "outputId": "05b471ed-e62f-4e2e-d4cd-40bb2f597747",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import PIL\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "# 2 - Loading Pretrained Facenet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T17:03:28.681504Z",
     "iopub.status.busy": "2024-12-21T17:03:28.680450Z",
     "iopub.status.idle": "2024-12-21T17:03:52.165248Z",
     "shell.execute_reply": "2024-12-21T17:03:52.163904Z",
     "shell.execute_reply.started": "2024-12-21T17:03:28.681458Z"
    },
    "executionInfo": {
     "elapsed": 15679,
     "status": "ok",
     "timestamp": 1690727308458,
     "user": {
      "displayName": "Diaa Essam",
      "userId": "00529409558760259485"
     },
     "user_tz": -180
    },
    "id": "T8UCzoyqfCd_",
    "outputId": "c20a4ea6-8b34-4e34-d891-a71ddac5f096",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "model = tf.keras.models.load_model('/Users/harshsingh/Desktop/projects/face/model')\n",
    "FRmodel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T17:03:56.637550Z",
     "iopub.status.busy": "2024-12-21T17:03:56.637122Z",
     "iopub.status.idle": "2024-12-21T17:03:56.709658Z",
     "shell.execute_reply": "2024-12-21T17:03:56.708093Z",
     "shell.execute_reply.started": "2024-12-21T17:03:56.637509Z"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1690727308458,
     "user": {
      "displayName": "Diaa Essam",
      "userId": "00529409558760259485"
     },
     "user_tz": -180
    },
    "id": "LVRONqzIfCeA",
    "outputId": "6eecd868-1469-42e7-bc96-bd68eb72b58b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 160, 160, 3) dtype=float32 (created by layer 'input_1')>]\n",
      "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'Bottleneck_BatchNorm')>]\n"
     ]
    }
   ],
   "source": [
    "print(model.inputs)\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "# 4 - Function to preprocess images and predict them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T12:38:23.065404Z",
     "iopub.status.busy": "2023-08-08T12:38:23.065015Z",
     "iopub.status.idle": "2023-08-08T12:38:23.143049Z",
     "shell.execute_reply": "2023-08-08T12:38:23.141852Z",
     "shell.execute_reply.started": "2023-08-08T12:38:23.065367Z"
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1690727353157,
     "user": {
      "displayName": "Diaa Essam",
      "userId": "00529409558760259485"
     },
     "user_tz": -180
    },
    "id": "lUOe34cxfCeD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def img_to_encoding(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(160, 160))\n",
    "    img = np.around(np.array(img) / 255.0, decimals=12)\n",
    "    x_train = np.expand_dims(img, axis=0) # add a dimension of 1 as first dimension\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding / np.linalg.norm(embedding, ord=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "# 5 - Simulation of a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T12:38:23.146515Z",
     "iopub.status.busy": "2023-08-08T12:38:23.146088Z",
     "iopub.status.idle": "2023-08-08T12:38:32.864202Z",
     "shell.execute_reply": "2023-08-08T12:38:32.863Z",
     "shell.execute_reply.started": "2023-08-08T12:38:23.146473Z"
    },
    "executionInfo": {
     "elapsed": 6064,
     "status": "ok",
     "timestamp": 1690727928861,
     "user": {
      "displayName": "Diaa Essam",
      "userId": "00529409558760259485"
     },
     "user_tz": -180
    },
    "id": "s6tmL4n1fCeD",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "database = {}\n",
    "base_dir = \"/Users/harshsingh/Desktop/projects/face/indian celebrities dataset/cropped_data\"\n",
    "\n",
    "for name in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, name)\n",
    "    \n",
    "    # Ensure the path is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        database[name] = []  # Initialize an empty list for the name\n",
    "        count = 0  # Reset count for each person\n",
    "        \n",
    "        for image in os.listdir(folder_path):\n",
    "            if count == 3:  # Stop after 5 images\n",
    "                break\n",
    "            \n",
    "            img_path = os.path.join(folder_path, image)\n",
    "            \n",
    "            # Ensure the path is a valid file\n",
    "            if os.path.isfile(img_path):\n",
    "                # Process the image to get its embedding\n",
    "                embedding = img_to_encoding(img_path, FRmodel)\n",
    "                database[name].append(embedding)  # Add embedding to the list\n",
    "                count += 1  # Increment the count\n",
    "\n",
    "print(\"Database created successfully!\")\n",
    "\n",
    "\n",
    "# database[\"Harshil\"] = img_to_encoding(\"/Users/harshsingh/Desktop/face/images/Harshil/Harshil_closeup.jpeg\", FRmodel)\n",
    "# database[\"Harsh\"] = img_to_encoding(\"/Users/harshsingh/Desktop/face/images/Harsh/Harsh_abhi.jpeg\", FRmodel)\n",
    "# database[\"Aryan\"] = img_to_encoding(\"/Users/harshsingh/Desktop/face/images/Aryan/Aryan_closeup.jpeg\", FRmodel)\n",
    "# database[\"Sarang\"] = img_to_encoding(\"/Users/harshsingh/Desktop/face/images/Sarang/Sarang_closeup.jpeg\", FRmodel)\n",
    "# database[\"Papa\"] = img_to_encoding(\"/Users/harshsingh/Desktop/face/images/Papa/Papa_plane.jpeg\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database[\"abhay_deol\"][0][0][0] and the number of entries are 14\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"database[\"abhay_deol\"][0][0][0] and the number of entries are {len(database)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cep_LTCNfCeD"
   },
   "source": [
    "Load the images of Danielle and Kian:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "# 6 - Face Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T12:38:33.298611Z",
     "iopub.status.busy": "2023-08-08T12:38:33.297576Z",
     "iopub.status.idle": "2023-08-08T12:38:33.371393Z",
     "shell.execute_reply": "2023-08-08T12:38:33.370407Z",
     "shell.execute_reply.started": "2023-08-08T12:38:33.298573Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1690727980676,
     "user": {
      "displayName": "Diaa Essam",
      "userId": "00529409558760259485"
     },
     "user_tz": -180
    },
    "id": "kyZz_FuefCeF",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba2f317e79e15a2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database, model):\n",
    "    \n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    dist = 100\n",
    "    for embeddings in database[identity]:\n",
    "        dist = min(np.linalg.norm(tf.subtract(embeddings, encoding)), dist)\n",
    "    if dist < 0.9:\n",
    "        print(\"It's \" + str(identity) + \", welcome in!\")\n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        door_open = False\n",
    "    print(dist)\n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "peoples = [\"Harsh\", \"Harshil\",\"Aryan\", \"Sarang\", \"Papa\"] ### \"Papa\", \"Saran\", \"Sarang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not Papa, please go away\n",
      "1.3494343\n",
      "It's not Papa, please go away\n",
      "1.3059747\n",
      "It's not Papa, please go away\n",
      "1.0922953\n",
      "It's not Papa, please go away\n",
      "1.179243\n",
      "It's not Papa, please go away\n",
      "1.3380356\n",
      "It's not Papa, please go away\n",
      "1.1703198\n",
      "It's not Papa, please go away\n",
      "1.3531189\n",
      "It's not Papa, please go away\n",
      "1.2834737\n",
      "It's not Papa, please go away\n",
      "1.382893\n",
      "It's not Papa, please go away\n",
      "1.4386061\n",
      "It's not Papa, please go away\n",
      "1.4384489\n",
      "It's not Papa, please go away\n",
      "1.4638108\n",
      "It's not Papa, please go away\n",
      "1.3239197\n",
      "It's not Papa, please go away\n",
      "1.3198936\n",
      "It's not Papa, please go away\n",
      "1.402802\n",
      "It's not Papa, please go away\n",
      "1.485149\n",
      "It's not Papa, please go away\n",
      "1.4150637\n",
      "It's Papa, welcome in!\n",
      "0.0\n",
      "It's Papa, welcome in!\n",
      "0.6383572\n",
      "It's Papa, welcome in!\n",
      "0.55083877\n",
      "It's Papa, welcome in!\n",
      "0.5994069\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"images\"  # Path to the \"images\" folder\n",
    "for person in peoples:\n",
    "    person_folder = os.path.join(base_dir, person)\n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if os.path.exists(person_folder):\n",
    "        # Iterate through each image in the person's folder\n",
    "        for image_name in os.listdir(person_folder):\n",
    "            image_path = os.path.join(person_folder, image_name)\n",
    "            \n",
    "            # Check if it's an image file (optional check based on file extension)\n",
    "            if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                # Call the verify function for each image\n",
    "                verify(image_path, \"Papa\", database, FRmodel)\n",
    "            else:\n",
    "                print(f\"Skipping non-image file: {image_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-08-08T12:38:33.501964Z",
     "iopub.status.busy": "2023-08-08T12:38:33.501572Z",
     "iopub.status.idle": "2023-08-08T12:38:33.630354Z",
     "shell.execute_reply": "2023-08-08T12:38:33.62937Z",
     "shell.execute_reply.started": "2023-08-08T12:38:33.501933Z"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1690728191961,
     "user": {
      "displayName": "Diaa Essam",
      "userId": "00529409558760259485"
     },
     "user_tz": -180
    },
    "id": "H0tCHd8zfCeF",
    "outputId": "5564e0ca-be16-4688-d8e1-c4e952aa1c92",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's alok nath, welcome in!\n",
      "0.5377962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5377962, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"/Users/harshsingh/Desktop/projects/face/indian celebrities dataset/cropped_data/alok nath/62749_kweylwdatv_1499690485.jpg_cropped.jpg\", \"alok nath\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "# 7 - Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T12:38:33.633304Z",
     "iopub.status.busy": "2023-08-08T12:38:33.632318Z",
     "iopub.status.idle": "2023-08-08T12:38:33.711704Z",
     "shell.execute_reply": "2023-08-08T12:38:33.710758Z",
     "shell.execute_reply.started": "2023-08-08T12:38:33.633267Z"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1690728201646,
     "user": {
      "displayName": "Diaa Essam",
      "userId": "00529409558760259485"
     },
     "user_tz": -180
    },
    "id": "xrYbqqsVfCeG",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a04ff2b5fd1186f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def who_is_it(image_path, database, model):\n",
    "    \n",
    "    encoding =  img_to_encoding(image_path, model)\n",
    "\n",
    "    min_dist = 1000\n",
    "    identity = None\n",
    "    for (name, db_enc) in database.items():\n",
    "        for embeddings in db_enc:\n",
    "            dist = np.linalg.norm(tf.subtract(embeddings, encoding))\n",
    "\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                identity = name\n",
    "\n",
    "    if min_dist > 0.95:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "\n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.0\n",
      "it's amitabh_bachchan, the distance is 0.80792135\n",
      "it's amitabh_bachchan, the distance is 0.5087117\n",
      "it's amitabh_bachchan, the distance is 0.7683447\n",
      "it's amitabh_bachchan, the distance is 0.5892964\n",
      "it's amitabh_bachchan, the distance is 0.49335662\n",
      "it's amitabh_bachchan, the distance is 0.5859018\n",
      "it's amitabh_bachchan, the distance is 0.48762754\n",
      "it's amitabh_bachchan, the distance is 0.61005384\n",
      "it's amitabh_bachchan, the distance is 0.6217037\n",
      "it's amitabh_bachchan, the distance is 0.6129079\n",
      "it's amitabh_bachchan, the distance is 0.7551705\n",
      "it's amitabh_bachchan, the distance is 0.52519906\n",
      "it's amitabh_bachchan, the distance is 0.51231664\n",
      "it's amitabh_bachchan, the distance is 0.484094\n",
      "it's amitabh_bachchan, the distance is 0.67519695\n",
      "it's amitabh_bachchan, the distance is 0.56753206\n",
      "it's amitabh_bachchan, the distance is 0.5054322\n",
      "it's pawan_malhotra, the distance is 0.81601405\n",
      "it's amitabh_bachchan, the distance is 0.723988\n",
      "it's amitabh_bachchan, the distance is 0.4257183\n",
      "it's amitabh_bachchan, the distance is 0.597589\n",
      "it's amitabh_bachchan, the distance is 0.47757307\n",
      "it's amitabh_bachchan, the distance is 0.52538604\n",
      "it's amitabh_bachchan, the distance is 0.6839353\n",
      "it's amitabh_bachchan, the distance is 0.29640704\n",
      "it's amitabh_bachchan, the distance is 0.55439246\n",
      "it's amitabh_bachchan, the distance is 0.5193805\n",
      "it's amitabh_bachchan, the distance is 0.55932516\n",
      "it's amitabh_bachchan, the distance is 0.48636663\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "base = \"/Users/harshsingh/Desktop/face/Indian_actors_faces/amitabh_bachchan\"\n",
    "count = 0\n",
    "for images in os.listdir(base):\n",
    "      x, y=who_is_it(os.path.join(base, images), database, FRmodel)\n",
    "      if(x>0.95 or y!= \"amitabh_bachchan\"):\n",
    "            count = count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-08-08T12:38:33.715228Z",
     "iopub.status.busy": "2023-08-08T12:38:33.714773Z",
     "iopub.status.idle": "2023-08-08T12:38:33.930419Z",
     "shell.execute_reply": "2023-08-08T12:38:33.92942Z",
     "shell.execute_reply.started": "2023-08-08T12:38:33.715191Z"
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1690728812359,
     "user": {
      "displayName": "Diaa Essam",
      "userId": "00529409558760259485"
     },
     "user_tz": -180
    },
    "id": "b7v4YQijfCeG",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9c88c8ab87677503",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "075e7036-f1e3-45e3-849e-752bb32ac916",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735060701.727488 2495722 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M3\n",
      "W0000 00:00:1735060701.741831 2510333 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped face saved at: /Users/harshsingh/Desktop/projects/face/test_cropped.jpg\n",
      "Not in the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9629221, 'jeetendra')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Data_pipeline.crop_image import Cropping\n",
    "test_path = \"/Users/harshsingh/Desktop/projects/face/test.png\"\n",
    "output_path = \"/Users/harshsingh/Desktop/projects/face\"\n",
    "cropper = Cropping(test_path, output_path, \"test\", 0, 10)\n",
    "test_path = cropper.crop_faces()\n",
    "\n",
    "# Test 1 with Younes pictures\n",
    "who_is_it(test_path, database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'peoples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m people \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpeoples\u001b[49m:\n\u001b[1;32m      2\u001b[0m       verify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/harshsingh/Desktop/face/Indian_actors_faces/irrfan_khan/images (9).jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, people, database, FRmodel)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'peoples' is not defined"
     ]
    }
   ],
   "source": [
    "for people in peoples:\n",
    "      verify(\"/Users/harshsingh/Desktop/face/Indian_actors_faces/irrfan_khan/images (9).jpg\", people, database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 19136,
     "sourceId": 796646,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3575428,
     "sourceId": 6225021,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30527,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tf3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
